{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflowvisu\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Assemble our graph\n",
    "## Step 1: read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)\n",
    "mnist = mnist_data.read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: create palce holders for inputs and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 : Create weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False,\n",
    "name='global_step')\n",
    "\n",
    "# five layers and their number of neurons (tha last layer has 10 softmax neurons)\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "# Weights initialised with small random values between -0.2 and +0.2\n",
    "# When using RELUs, make sure biases are initialised with small *positive* values for example 0.1 = tf.ones([K])/10\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))  # 784 = 28 * 28\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([N]))\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "B4 = tf.Variable(tf.zeros([O]))\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 : Build maodel to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Specify loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6:Create Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase2 :Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#with tf.Session() as sess:\n",
    "    #sess.run(init_op)\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        X:batch[0], Y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={X: batch[0], Y_: batch[1]})\n",
    "  if (i + 1) % 1000==0:\n",
    "    saver.save(sess, './checkpoints/five_layers_sigmiod',\n",
    "    global_step=global_step)\n",
    "save_path = saver.save(sess, \"model20.ckpt\")\n",
    "print (\"Model saved in file: \", save_path)\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    X: mnist.test.images, Y_: mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See your model in Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1:\n",
    "\n",
    "Writer = tf.summary.Filewriter('./graphs’,sess.graph)\n",
    "\n",
    "## Step2:After running the program run this in terminal\n",
    "$tensorboard –logdir=’./graphs’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save our model every 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#with tf.Session() as sess:\n",
    "    #sess.run(init_op)\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        X:batch[0], Y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={X: batch[0], Y_: batch[1]})\n",
    "  if (i + 1) % 1000==0:\n",
    "    saver.save(sess, 'five_layers_sigmiod',\n",
    "    global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore our model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess, \"model2.ckpt\")\n",
    "        print (\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpoints/five_layers_sigmiod'))\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print (\"Latest model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Predict a handwritten integer (MNIST beginners).\n",
    "\n",
    "Script requires\n",
    "1) saved model (model.ckpt file) in the same location as the script is run from.\n",
    "(requried a model created in the MNIST beginners tutorial)\n",
    "2) one argument (png file location of a handwritten integer)\n",
    "\n",
    "Documentation at:\n",
    "http://niektemme.com/ @@to do\n",
    "\"\"\"\n",
    "\n",
    "#import modules\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image,ImageFilter\n",
    "import PIL.ImageOps    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import ndimage\n",
    "\n",
    "def predictint(imvalue):\n",
    "    \"\"\"\n",
    "    This function returns the predicted integer.\n",
    "    The input is the pixel values from the imageprepare() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the model (same as when creating the model file)\n",
    "   \n",
    "\n",
    "    # input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "    X = tf.placeholder(tf.float32, [None, 784])\n",
    "    # correct answers will go here\n",
    "    Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # five layers and their number of neurons (tha last layer has 10 softmax neurons)\n",
    "    L = 200 \n",
    "    M = 100\n",
    "    N = 60\n",
    "    O = 30\n",
    "    # Weights initialised with small random values between -0.2 and +0.2\n",
    "    # When using RELUs, make sure biases are initialised with small *positive* values for example 0.1 = tf.ones([K])/10\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))  # 784 = 28 * 28\n",
    "    B1 = tf.Variable(tf.zeros([L]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.zeros([M]))\n",
    "    W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "    B3 = tf.Variable(tf.zeros([N]))\n",
    "    W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "    B4 = tf.Variable(tf.zeros([O])) \n",
    "    W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "    B5 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    # The model\n",
    "    #XX = tf.reshape(X, [-1, 784])\n",
    "    Y1 = tf.nn.sigmoid(tf.matmul(X, W1) + B1)\n",
    "    Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)\n",
    "    Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)\n",
    "    Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)\n",
    "    Ylogits = tf.matmul(Y4, W5) + B5\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "    # TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "    # problems with log(0) which is NaN\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "    # accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    \"\"\"\n",
    "    Load the model.ckpt file\n",
    "    file is stored in the same directory as this python script is started\n",
    "    Use the model to predict the integer. Integer is returend as list.\n",
    "\n",
    "    Based on the documentatoin at\n",
    "    https://www.tensorflow.org/versions/master/how_tos/variables/index.html\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess, \"model2.ckpt\")\n",
    "        print (\"Model restored.\")\n",
    "   \n",
    "        prediction=tf.argmax(Y,1)\n",
    "        return prediction.eval(feed_dict={X: [imvalue]}, session=sess)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
